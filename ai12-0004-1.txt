!standard 2.1(4.1/2)                               11-11-08    AI12-0004-1/01
!class Amendment 11-11-08
!status work item 11-11-08
!status received 11-06-20
!priority Low
!difficulty Medium
!subject Normalization and allowed characters for identifiers
!summary

[Editor's note: This AI is formatted in UTF-8 rather than the typical ASCII because
the character examples need extended characters.]

**TBD.

!question

(1) 2.1(4.1/2) says that meaning of program text not in Normalization Form KC is
"implementation-defined". An Ada implementation could reject such text, even if
it is only used in characters and/or string literals. But Normalization Form KC
is very strong, including such things as superscript and subscript characters
(so that writing m² rather than m**2 would not be allowed).

The Unicode identifier recommendations included by reference in ISO/IEC 10646:2011
suggest that Normalization Form KC should be applied to identifiers (only). There
is no reason to apply such a form to the remainder of Ada text, and especially to
allow implementations to reject programs that contain characters not allowed by
that form. Should this permission be restricted to identifiers? (Yes.)

(2) The Unicode identifier recommendations included by reference in ISO/IEC 10646:2011
(this is Annex 31, the current link as of this writing is
http://www.unicode.org/reports/tr31/tr31-13.html) suggests using the character classes
XID_Start and XID_Continue in identifiers. The classes are defined to be stable,
such that future character set standards (Unicode and 10646 now are kept fairly close
together) will only make upwardly compatible changes. That is not true of character
classes like "letter_uppercase", which is what Ada is currently defined in terms of.

Should we consider changing to use these classes? (Yes.)

!proposal

(1) Normalization is only relevant for identifiers. Text in comments, strings, and
the like should not be normalized. (The current implementation-defined rule should
not apply there, as it is too strong.)

Ada should require normalization ONLY for the purpose of comparing identifiers for
equivalence (along with case folding). And it should not make anything about this
implementation-defined (for portability reasons). This would eliminate the current
problem that some allowed identifier characters should be avoided simply because
implementations might treat them differently (or not allow them at all).

(2) Ada should use XId_Start and XID_Continue, with the special rules Ada currently
has for "punctuation_connector" kept (that's underscore).

**TBD: The editor did not carefully check the effects of making this change. In
particular, what incompatibilities (if any) would occur. For the most part, other
than "stability extensions", these classes match what we do anyway (which is
probably because our definition came originally from an earlier version of TR31).
So I would expect incompatibilities to be minor (if there are any at all).

**TBD: If we depend identifiers on these classes, we should consider adding
categorization functions for these classes to Ada.Wide_Characters.Handling,
along with a comparison function, so that we have direct support
for identifier handling in the predefined libraries. That would let us get rid
of the silly notes that tell users to not depend on these routines for
processing Ada identifiers.

!wording

** TBD.

!discussion

As noted in the question, Annex U of ISO/IEC 10646:2011 directly references the
Unicode Annex 31 document. It's fairly clear that this is the recommendation of the
experts in this field, and we should come as close to those recommendations
as possible. (But don't forget AI05-0227-1 about case folding and upper case
conversions -- we should not undo those corrections.)

Note that applying Normalization Form KC to identifiers will make many more identifiers
act as identical. For instance "m2" and "m²" and "M2" are all considered the same.
This probably is a good thing, as it requires identifiers to be significantly different.

!ACATS test

** TBD.

!ASIS

** TBD.

!appendix

!topic Inconsistency in text normalization form and allowed characters
!reference Ada 2012 RM (Draft 12) 2.1(4.1/2), 2.2(3/2), 2.3(8.c/2), A.3.2(60/3), A.4.6(8/3), AI05-0114-1
!from Howard W. Ludwig 11-06-20
!discussion

2.1(4.1/2) states The semantics of an Ada program whose text is not in Normalization Form KC
(as defined by section 24 of ISO/IEC 10646:2003) is implementation defined.

This adheres to recommendations for communicating case-insensitive data across a network in a manner
minimizing security issues. However, it raises two difficulties (the first of which has shades of
leap second):

1.

AI-0114-1 indicates a ruling that characters such as the feminine ordinal indicator (Unicode code
point u+00AA), the micro sign (u+00B5), and the masculine ordinal indicator (u+00BA) are to be
regarded as letters (because Unicode places them in category Ll, lower-case letters) that can be
used in identifiers, but are not to be treated as letters by Ada.Characters.Handling.Is_Letter.
However, Normalization Form KC does not allow the use of those characters (with ª being replaced by
a [u+0061], µ replaced by μ [u+03BC], and º replaced by o [u+006F]). If a programmer wishes to avoid
implementation-defined behavior, then the use of these (and some other) characters in identifiers is
forbidden. In any case, it would seem that an Ada compiler, due to Ada’s case insensitivity, must at
the very least treat the identifier ª as identical to the identifiers A and a. In addition, the
AARM 2.3(8.c/2) indicates, in contradiction to the NFKC expectation: An identifier can use any letter
defined by ISO-10646:2003, along with several other categories.

2.

Normalization Form KC forbids the use of superscripted and subscripted digits, for example. While I
understand motivation for this restriction as applied to identifiers, I really would like to be able
to use the full Unicode character set in comments. For example, if I declare a variable Area and I
would like to indicate in commentary that its units are square meters, I would like to be able to
write it as:

Area: Float := 0.0;  -- m²

This is illegal in NFKC. A tool that converts an arbitrary text file to NFKC would convert this to:

Area: Float := 0.0;  -- m2

unsuperscripting the 2 so that it is no longer obvious that squaring is intended to be indicated. I
would like to see comments being explicitly exempted from the Normalization Form KC expectation
indicated by 2.1(4.1/2).

Given all these issues, it might be more straightforward to use Normalization Form C instead of
KC in 2.1(4.1/2).

****************************************************************

From: Randy Brukardt
Sent: Friday, July 1, 2011  7:39 PM

>2.1(4.1/2) states The semantics of an Ada program whose text is not in 
>Normalization Form KC (as defined by section 24 of ISO/IEC 10646:2003) 
>is implementation defined.

>This adheres to recommendations for communicating case-insensitive data 
>across a network in a manner minimizing security issues.

My recollection is that this was inserted in order to sort-of follow a Unicode recommendation. We
originally required the compiler to convert the source to Normalization Form KC before processing.
However, there was great concern that this conversion could make identifiers that look very different
(and likely compare differently in editors) be treated as the same. Of course, the reverse also could
be true. So this rule was added, with the intent that it would leave it up to implementors as to whether
or not the normalization was performed.

[I should point out that those Unicode recommendations were completely rewritten between Unicode 4
(which is what Ada 2005 uses) and Unicode 5 -- completely reversing the recommendations in some areas.
So I don't know what is recommended now on this specific topic.]

>...However, it
>raises two difficulties (the first of which has shades of leap second):

>1.
>
>AI-0114-1 indicates a ruling that characters such as the feminine 
>ordinal indicator (Unicode code point u+00AA), the micro sign (u+00B5), 
>and the masculine ordinal indicator (u+00BA) are to be regarded as 
>letters (because Unicode places them in category Ll, lower-case 
>letters) that can be used in identifiers, but are not to be treated as letters by
>Ada.Characters.Handling.Is_Letter.
>However, Normalization Form KC does not allow the use of those 
>characters (with ª being replaced by a [u+0061], µ replaced by µ [u+03BC], and º replaced by o [u+006F]).
>If a programmer wishes to avoid implementation-defined behavior, then 
>the use of these (and some other) characters in identifiers is forbidden.

I agree with this.

>In any case, it would seem that an Ada compiler, due to Ada’s case 
>insensitivity, must at the very least treat the identifier ª as identical to the identifiers A and a.

Now I've lost you. If the compiler implements the normalization, then it will never see ª in an identifier.
Otherwise, the letter (if not normalized) is clearly *not* the same as A (based on the case folding tables).
The net effect is that a compiler could do it either way and be within the requirements of the language.
After all, "implementation-defined" is just that; the compiler could set off a fireworks show (this being
the July 4th weekend) if it wanted to when the source text is not in Normalization Form KC; pretty much
anything goes so long as it is documented. We probably would have preferred to restrict the outcomes
but that isn't really an option given the framework of the Ada Standard.

>In addition, the AARM 2.3(8.c/2) indicates, in contradiction to the NFKC expectation:
>An identifier can use any letter defined by ISO-10646:2003, along with several other categories.

The AARM, of course, is not normative, and it is discussing the language ignoring NFKC issues. I'm
actually surprised to hear that NFKC eliminates some characters completely, as that seems like a bad
thing. In any case, if the compiler does not normalize the source input before processing, then the AARM
note is strictly true. (I believe that all existing Ada 2005 compilers don't normalize.) 

>2. Normalization Form KC forbids the use of superscripted and 
>subscripted digits, for example. While I understand motivation for this 
>restriction as applied to identifiers, I really would like to be able 
>to use the full Unicode character set in comments. For example, if I 
>declare a variable Area and I would like to indicate in commentary that its units are square meters,
>I would like to be able to write it as:
>
>	Area: Float := 0.0;  -- m²
>
>This is illegal in NFKC. A tool that converts an arbitrary text file to 
>NFKC would convert this to:
>
>	Area: Float := 0.0;  -- m2
>
>	unsuperscripting the 2 so that it is no longer obvious that squaring 
>is intended to be indicated. I would like to see comments being 
>explicitly exempted from the Normalization Form KC expectation indicated by 2.1(4.1/2).

The intent was that a compiler could normalize all of the source, or leave the source in its original form.
In either case, comments would have the same effect. It would greatly complicate the implementation to turn
normalization on and off in different places, and it would violate the Unicode recommendation that all source
code be intepreted in NFKC.

Unless the implementation does something silly (like the fireworks-generating compiler noted earlier), the
effect of comments would be the same either way. So I don't think there is any need to avoid any characters
in comments.

>Given all these issues, it might be more straightforward to use Normalization Form C instead of KC in 2.1(4.1/2).

If there actually were any issues, it probably would be better to simply drop any permission for normalization,
since it appears to be actively harmful (but it really isn't that harmful, as noted above). I find eliminating
superscripts and subscripts to be completely changing the meaning of the text (as you note in your comments),
that goes so far beyond normalization that it is simply insane. Moreover, if we are going to ignore the Unicode
recommendation in this area (as we had to do for identifiers, see AI05-0227-1 for the sad details), we might
as well go all the way and ignore normalization altogether.

In any case, this is too late for Ada 2012; the earliest that the ARG could take up this issue would be at the
November meeting, and the final draft of Ada 2012 should have been approved before that meeting. So this will
be an early Ada 2012 AI and possible Binding Interpretation.

****************************************************************

From: Howard W Ludwig
Sent: Tuesday, July 5, 2011  2:26 PM

...
>[I should point out that those Unicode recommendations were completely 
>rewritten between Unicode 4 (which is what >Ada 2005 uses) and Unicode
>5 -- completely reversing the recommendations in some areas. So I don't 
>know what is >recommended now on this specific topic.]

I understand that the rules for Unicode 5 and Ada 2012 changed from the previous version and why. The changes
seem sensible, and it could get problematic for Unicode and Ada to diverge unnecessarily. NFKC is a Unicode
recommendation for text interpreted in a case-insensitive manner (NFC for case-sensitive), so I can see how
2.1(4.1/2) was established, although it does have troubling consequences (mentioned below) accompanying
certain advantages.

...
>>In any case, it would seem that an Ada compiler, due to Ada’s case 
>>insensitivity, must at the very least treat the identifier ª as 
>>identical to the identifiers A and a.
>
>Now I've lost you. If the compiler implements the normalization, then it will never see ª in an identifier.
>Otherwise, the letter (if not normalized) is clearly *not* the same as A (based on the case folding tables).
>The net effect is that a compiler could do it either way and be within the requirements of the language.
>After all, "implementation-defined" is just that; the compiler could set off a fireworks show (this being
>the July 4th >weekend) if it wanted to when the source text is not in Normalization Form KC; pretty much
>anything goes so long as it is documented. We probably would have preferred to restrict the outcomes but
>that isn't really an option given the framework of the Ada Standard.

My point was based on my interpretation of the implementation-dependence of source code written in other
than NFKC [2.1(4.1/2)]. I regarded this as being my responsibility to write the code in NFKC so the compiler
would behave in a ARM-defined and -compliant manner. If that is the case, then I must not use ª, µ [u+00B5],
and º identifiers in my code, because they are not legal for NFKC. I see your point that the compiler could
do the normalization for me (somewhat like a preprocessor); however, if that happens, the compiler would
replace ª by a and º by o, effectively making the identifier ª identical to the identifiers A and a--this is
what I was really making reference to in my original statement where you lost me. The whole point of
normalization is to clarify when two characters are clearly intended to be the same but are written as text
with different code points (for example, å can be written as the simple u+00E5 or as the compound u+0061 u+030A,
for which NFKC requires the former and a conversion tool u+would recognize the latter
and convert it to the former). The different normalization forms provide different prescriptions as to when
two different sequences of code points are to be treated as the same character. NFC is very simple and would say,
like NFKC, that å should be written as u+00E5 and not as u+0061 u+030A; NFD and NFKD make the opposite choice.
However, NFKC goes way beyond NFC and makes many more sequences of code points identical, so that font effects
like subscripting, superscripting, bolding, etc. are treated as insignificant to meaning and only the unadorned
character version code point is to be accepted (ª gets converted to a, for example).

I understand about "implementation-defined" allowing fireworks as long as it is documented. If I comply with
NFKC in my code, I will not use those three characters myself, even though the ARM explicitly states they
are legal in identifiers; if the compiler does the normalization for me, then it will eliminate those characters
(even though explicitly allowed) and remap them as I stated before; otherwise, the compiler can do anything
(treat ª as the same as a, treat ª as totally distinct from a, or generate fireworks).  That is why I try to
avoid implementation- dependence, so I don't have to worry about such variations. In this case, it means I need
to write my code as NFKC to avoid one compiler generating fireworks while another compiler does what I had
hoped it would do. That is why I am making somewhat of a big deal about this.

...
>The intent was that a compiler could normalize all of the source, or leave
>the source in its original form. In >either case, comments would have the same effect.
>It would greatly complicate the implementation to turn
>normalization on and off in different places, and it would violate the
>Unicode recommendation that all source code be interpreted in NFKC.
>
>Unless the implementation does something silly (like the fireworks-generating compiler
>noted earlier), the effect of comments would be the same either way. So I don't think
there is any need to avoid any characters in comments.

If the compiler does the normalization to NFKC and any generated listings are produced after
the normalization, my superscripts would be undone in the listing. (My understanding is that
nnex H, if supported by a compiler, requires a compiler to be able to generate listings, potentially
with generated assembly language, to enable certain security reviews, and it is wide open how that
is done, so post-normalization listings are quite plausible.)

The other (and to me more important) issue is that, with the implementation-dependence for
non-NFKC source code, the compiler might refuse to accept non-NFKC text (with or without
accompanying fireworks), which would prevent me from using the superscripts if I want my code
compiled, unless there are explicit ARM constraints forbidding rejecting code solely because comments
are not written in NFKC.

>>Given all these issues, it might be more straightforward to use
Normalization Form C instead of KC in 2.1(4.1/2).
>
>If there actually were any issues, it probably would be better to simply drop any permission for
>normalization, since it appears to be actively harmful (but it really isn't that harmful, as noted
>above). I find eliminating superscripts and subscripts to be completely changing the meaning of the
>text (as you note in your comments), that goes so far beyond normalization that it is simply insane.
>Moreover, if we are going to ignore the Unicode recommendation in this area (as we had to do for
>identifiers, see AI05-0227-1 for the sad details), we might as >well go all the way and ignore
>normalization altogether.

I agree with your insanity comment, but that is what NFKC and NFKD do. (NFC and NFD are far more sane
in this regard.) However, as I pointed out earlier, the normalization is useful for letting all parties
know how to indicate in a clear, unique, unambiguous manner a particular character that otherwise has
multiple ways of being expressed, so it seems a little dangerous to throw out the whole thing. I know
that WG9 in general and Robert Dewar have had fun dealing with case insensitivity in the context of
the German ß versus SS and ss, as well as the Turkish lower-case dotless and dotted i both being
written as I in upper case. Character composition and character compatibility in Unicode just extend
these issues into a broader realm with more cans of worms (which is why I alluded to the leap second
issues that proved difficult to close completely in a self-consistent manner).

>In any case, this is too late for Ada 2012; the earliest that the ARG could
>take up this issue would be at the November meeting, and the final draft of Ada 2012 should have been
approved before that meeting. So this will be an early Ada 2012 AI and possible Binding Interpretation.

I understand that progress has to be made, and at some point you have to say you are done for a given
phase or stage, and you move on. I do not wish to cause a delay in releasing Ada 2012. I still
appreciate your consideration at some point, as well as WG9's desire to have Ada becoming an ever better
language without breaking what people may already be using.

****************************************************************
